{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Hub**"
      ],
      "metadata": {
        "id": "vdseL9Zuv7e-"
      },
      "id": "vdseL9Zuv7e-"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "\n",
        "# Load the model from TensorFlow Hub\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(model_url, input_shape=(224, 224, 3))\n",
        "])\n",
        "\n",
        "# Example: Using the model for inference\n",
        "import numpy as np\n",
        "\n",
        "# Load an example image (replace 'your_image.jpg' with the path to your image)\n",
        "img = tf.keras.preprocessing.image.load_img('/content/sample_data/ronaldo.jpg', target_size=(224, 224))\n",
        "img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis=0) / 255.0\n",
        "\n",
        "# Predict the class of the image\n",
        "predictions = model.predict(img)\n",
        "predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "KM7eAKYotbnA",
        "outputId": "9d48164b-47f3-4579-8740-42521fdb49e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KM7eAKYotbnA",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 683ms/step\n",
            "Predicted class: [615]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file of 10_food_classes images\n",
        "# See how this data was created - https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Y1_l7zWbt1Cd",
        "outputId": "81dbae32-bc3a-4c82-b79c-da2489e589f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y1_l7zWbt1Cd",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-16 15:53:57--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.207, 74.125.20.207, 108.177.98.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  26.5MB/s    in 9.9s    \n",
            "\n",
            "2024-06-16 15:54:07 (50.2 MB/s) - ‘10_food_classes_all_data.zip’ saved [519183241/519183241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import EfficientNetB0\n",
        "from keras.layers import Dense, Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "Bf1j_7-vwV-1"
      },
      "id": "Bf1j_7-vwV-1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224) # define image size\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=\"/content/10_food_classes_all_data/train\",\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=32) # batch_size is 32 by default, this is generally a good number\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=\"/content/10_food_classes_all_data/test\",\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "nvinvvyXw7qG",
        "outputId": "b51f35f4-1c0a-4e64-adf5-97a211eeeb07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nvinvvyXw7qG",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "HgsHG1IbxEtk"
      },
      "id": "HgsHG1IbxEtk",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Setup checkpoint path\n",
        "checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\" # note: remember saving directly to Colab is temporary\n",
        "\n",
        "# Create a ModelCheckpoint callback that saves the model's weights only\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True, # set to False to save the entire model\n",
        "                                                         save_best_only=True, # save only the best model weights instead of a model every epoch\n",
        "                                                         save_freq=\"epoch\", # save every epoch\n",
        "                                                         verbose=1)\n",
        "\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
        "                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n",
        "\n",
        "\n",
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, # print out when learning rate goes down\n",
        "                                                 min_lr=1e-7)"
      ],
      "metadata": {
        "id": "TsfXGs7jxc7R"
      },
      "id": "TsfXGs7jxc7R",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNetV2\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNetV2 inputs don't have to be normalized)\n",
        "x = base_model(inputs)\n",
        "# Check data shape after passing it to base_model\n",
        "print(f\"Shape after base_model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model (we use less steps for validation so it's faster)\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data_10_percent,\n",
        "                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n",
        "                                 validation_steps=int(0.25 * len(test_data_10_percent)),\n",
        "                                 # Track our model's training logs for visualization later\n",
        "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])"
      ],
      "metadata": {
        "id": "0GjmtTElxW9N",
        "outputId": "e4805ca9-3575-4de0-922e-971eb2e0e120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0GjmtTElxW9N",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After GlobalAveragePooling2D(): (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extract/20240616-155855\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 32s 98ms/step - loss: 0.8375 - accuracy: 0.7688 - val_loss: 0.4091 - val_accuracy: 0.8947\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 19s 80ms/step - loss: 0.4685 - accuracy: 0.8617 - val_loss: 0.3580 - val_accuracy: 0.8997\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 19s 80ms/step - loss: 0.3975 - accuracy: 0.8824 - val_loss: 0.3180 - val_accuracy: 0.9145\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 24s 102ms/step - loss: 0.3565 - accuracy: 0.8940 - val_loss: 0.3123 - val_accuracy: 0.9178\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 20s 81ms/step - loss: 0.3249 - accuracy: 0.9029 - val_loss: 0.2976 - val_accuracy: 0.9243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "data_augmentation = keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "  layers.RandomZoom(0.2),\n",
        "  layers.RandomHeight(0.2),\n",
        "  layers.RandomWidth(0.2),\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetV2B0\n",
        "], name =\"data_augmentation\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KqNA3Cdlx1-6"
      },
      "id": "KqNA3Cdlx1-6",
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
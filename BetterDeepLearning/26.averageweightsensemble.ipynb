{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "M2fNt6H8VRbF",
        "outputId": "2108ab04-008e-48d0-c1c6-558001faf8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-264db3d54530>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# develop an mlp for blobs dataset\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=2, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=0)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot loss learning curves\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy learning curves\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy', pad=-40)\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save models to file toward the end of a training run\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=2, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "n_epochs, n_save_after = 500, 490\n",
        "for i in range(n_epochs):\n",
        "  # fit model for a single epoch\n",
        "  model.fit(trainX, trainy, epochs=1, verbose=1)\n",
        "  # check if we should save the model\n",
        "  if i >= n_save_after:\n",
        "    model.save('model_' + str(i) + '.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWS2v2MvWhAH",
        "outputId": "475dec71-69cd-440d-f02c-9c3d22cc5195"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 3ms/step - loss: 1.0067 - accuracy: 0.4400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9681 - accuracy: 0.4500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9385 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8967 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8674 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.4700\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8264 - accuracy: 0.4600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8153 - accuracy: 0.4700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8061 - accuracy: 0.4800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7970 - accuracy: 0.5100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7882 - accuracy: 0.5100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7809 - accuracy: 0.5400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.5700\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.5900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.6000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.6100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.6300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.6400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7321 - accuracy: 0.6500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.6800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7216 - accuracy: 0.6900\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7164 - accuracy: 0.6900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.6900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.6900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.6900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.7000\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6415 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5293 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5249 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5206 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5003 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7600\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7700\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7900\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3642 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3441 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3429 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3438 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8600\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3418 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3393 - accuracy: 0.8600\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8700\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3378 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3376 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8400\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#average the weights of multiple loaded models\n",
        "from keras.models import load_model\n",
        "from keras.models import clone_model\n",
        "from numpy import average\n",
        "from numpy import array\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_start, n_end):\n",
        "  all_models = list()\n",
        "  for epoch in range(n_start, n_end):\n",
        "    # define filename for this ensemble\n",
        "    filename = '/content/model_' + str(epoch) + '.h5'\n",
        "    # load model from file\n",
        "    model = load_model(filename)\n",
        "    # add to list of members\n",
        "    all_models.append(model)\n",
        "    print('>loaded %s' % filename)\n",
        "  return all_models\n",
        "\n",
        "# create a model from the weights of multiple models\n",
        "def model_weight_ensemble(members, weights):\n",
        "  # determine how many layers need to be averaged\n",
        "  n_layers = len(members[0].get_weights())\n",
        "  # create an set of average model weights\n",
        "  avg_model_weights = list()\n",
        "  for layer in range(n_layers):\n",
        "    # collect this layer from each model\n",
        "    layer_weights = array([model.get_weights()[layer] for model in members])\n",
        "    # weighted average of weights for this layer\n",
        "    avg_layer_weights = average(layer_weights, axis=0, weights=weights)\n",
        "    # store average layer weights\n",
        "    avg_model_weights.append(avg_layer_weights)\n",
        "  # create a new model with the same structure\n",
        "  model = clone_model(members[0])\n",
        "  # set the weights in the new\n",
        "  model.set_weights(avg_model_weights)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# load all models into memory\n",
        "members = load_all_models(490, 500)\n",
        "print('Loaded %d models' % len(members))\n",
        "# prepare an array of equal weights\n",
        "n_models = len(members)\n",
        "weights = [1/n_models for i in range(1, n_models+1)]\n",
        "# create a new model with the weighted average of all model weights\n",
        "model = model_weight_ensemble(members, weights)\n",
        "# summarize the created model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QPlyLiQhDkG",
        "outputId": "c8f6dac9-f877-4368-9251-85bb42081a25"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">loaded /content/model_490.h5\n",
            ">loaded /content/model_491.h5\n",
            ">loaded /content/model_492.h5\n",
            ">loaded /content/model_493.h5\n",
            ">loaded /content/model_494.h5\n",
            ">loaded /content/model_495.h5\n",
            ">loaded /content/model_496.h5\n",
            ">loaded /content/model_497.h5\n",
            ">loaded /content/model_498.h5\n",
            ">loaded /content/model_499.h5\n",
            "Loaded 10 models\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_34 (Dense)            (None, 25)                75        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 78        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153 (612.00 Byte)\n",
            "Trainable params: 153 (612.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average of model weights on blobs problem\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.models import clone_model\n",
        "from matplotlib import pyplot\n",
        "from numpy import average\n",
        "from numpy import array\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_start, n_end):\n",
        "  all_models = list()\n",
        "  for epoch in range(n_start, n_end):\n",
        "    # define filename for this ensemble\n",
        "    filename = '/content/model_' + str(epoch) + '.h5'\n",
        "    # load model from file\n",
        "    model = load_model(filename)\n",
        "    # add to list of members\n",
        "    all_models.append(model)\n",
        "    print('>loaded %s' % filename)\n",
        "  return all_models\n",
        "\n",
        "# # create a model from the weights of multiple models\n",
        "def model_weight_ensemble(members, weights):\n",
        "  # determine how many layers need to be averaged\n",
        "  n_layers = len(members[0].get_weights())\n",
        "  # create an set of average model weights\n",
        "  avg_model_weights = list()\n",
        "  for layer in range(n_layers):\n",
        "    # collect this layer from each model\n",
        "    layer_weights = array([model.get_weights()[layer] for model in members])\n",
        "    # weighted average of weights for this layer\n",
        "    avg_layer_weights = average(layer_weights, axis=0, weights=weights)\n",
        "    # store average layer weights\n",
        "    avg_model_weights.append(avg_layer_weights)\n",
        "  # create a new model with the same structure\n",
        "  model = clone_model(members[0])\n",
        "  # set the weights in the new\n",
        "  model.set_weights(avg_model_weights)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "  # select a subset of members\n",
        "  subset = members[:n_members]\n",
        "  # prepare an array of equal weights\n",
        "  weights = [1.0/n_members for i in range(1, n_members+1)]\n",
        "  # create a new model with the weighted average of all model weights\n",
        "  model = model_weight_ensemble(subset, weights)\n",
        "  # make predictions and evaluate accuracy\n",
        "  _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "  return test_acc\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# load models in order\n",
        "members = load_all_models(490, 500)\n",
        "print('Loaded %d models' % len(members))\n",
        "# reverse loaded models so we build the ensemble with the last models first\n",
        "members = list(reversed(members))\n",
        "# evaluate different numbers of ensembles on hold out set\n",
        "single_scores, ensemble_scores = list(), list()\n",
        "for i in range(1, len(members)+1):\n",
        "  # evaluate model with i members\n",
        "  ensemble_score = evaluate_n_members(members, i, testX, testy)\n",
        "  # evaluate the i'th model standalone\n",
        "  _, single_score = members[i-1].evaluate(testX, testy, verbose=0)\n",
        "  # summarize this step\n",
        "  print('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
        "  ensemble_scores.append(ensemble_score)\n",
        "  single_scores.append(single_score)\n",
        "# plot score vs number of ensemble members\n",
        "x_axis = [i for i in range(1, len(members)+1)]\n",
        "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
        "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "uzoboXw1iMA9",
        "outputId": "7bb691e1-ffc5-40b5-a93d-6a7f19689a96"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">loaded /content/model_490.h5\n",
            ">loaded /content/model_491.h5\n",
            ">loaded /content/model_492.h5\n",
            ">loaded /content/model_493.h5\n",
            ">loaded /content/model_494.h5\n",
            ">loaded /content/model_495.h5\n",
            ">loaded /content/model_496.h5\n",
            ">loaded /content/model_497.h5\n",
            ">loaded /content/model_498.h5\n",
            ">loaded /content/model_499.h5\n",
            "Loaded 10 models\n",
            "> 1: single=0.802, ensemble=0.802\n",
            "> 2: single=0.802, ensemble=0.802\n",
            "> 3: single=0.804, ensemble=0.804\n",
            "> 4: single=0.808, ensemble=0.804\n",
            "> 5: single=0.809, ensemble=0.804\n",
            "> 6: single=0.809, ensemble=0.807\n",
            "> 7: single=0.810, ensemble=0.808\n",
            "> 8: single=0.808, ensemble=0.808\n",
            "> 9: single=0.811, ensemble=0.807\n",
            "> 10: single=0.811, ensemble=0.808\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linearly decreasing weighted average of models on blobs problem\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.models import clone_model\n",
        "from matplotlib import pyplot\n",
        "from numpy import average\n",
        "from numpy import array\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_start, n_end):\n",
        "  all_models = list()\n",
        "  for epoch in range(n_start, n_end):\n",
        "    # define filename for this ensemble\n",
        "    filename = '/content/model_' + str(epoch) + '.h5'\n",
        "    # load model from file\n",
        "    model = load_model(filename)\n",
        "    # add to list of members\n",
        "    all_models.append(model)\n",
        "    print('>loaded %s' % filename)\n",
        "  return all_models\n",
        "\n",
        "# create a model from the weights of multiple models\n",
        "def model_weight_ensemble(members, weights):\n",
        "  # determine how many layers need to be averaged\n",
        "  n_layers = len(members[0].get_weights())\n",
        "  # create an set of average model weights\n",
        "  avg_model_weights = list()\n",
        "  for layer in range(n_layers):\n",
        "    # collect this layer from each model\n",
        "    layer_weights = array([model.get_weights()[layer] for model in members])\n",
        "    # weighted average of weights for this layer\n",
        "    avg_layer_weights = average(layer_weights, axis=0, weights=weights)\n",
        "    # store average layer weights\n",
        "    avg_model_weights.append(avg_layer_weights)\n",
        "  # create a new model with the same structure\n",
        "  model = clone_model(members[0])\n",
        "  # set the weights in the new\n",
        "  model.set_weights(avg_model_weights)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "  # select a subset of members\n",
        "  subset = members[:n_members]\n",
        "  # prepare an array of linearly decreasing weights\n",
        "  weights = [i/n_members for i in range(n_members, 0, -1)]\n",
        "  # create a new model with the weighted average of all model weights\n",
        "  model = model_weight_ensemble(subset, weights)\n",
        "  # make predictions and evaluate accuracy\n",
        "  _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "  return test_acc\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# load models in order\n",
        "members = load_all_models(490, 500)\n",
        "print('Loaded %d models' % len(members))\n",
        "# reverse loaded models so we build the ensemble with the last models first\n",
        "members = list(reversed(members))\n",
        "# evaluate different numbers of ensembles on hold out set\n",
        "single_scores, ensemble_scores = list(), list()\n",
        "for i in range(1, len(members)+1):\n",
        "  # evaluate model with i members\n",
        "  ensemble_score = evaluate_n_members(members, i, testX, testy)\n",
        "  # evaluate the i'th model standalone\n",
        "  _, single_score = members[i-1].evaluate(testX, testy, verbose=0)\n",
        "  # summarize this step\n",
        "  print('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
        "  ensemble_scores.append(ensemble_score)\n",
        "  single_scores.append(single_score)\n",
        "# plot score vs number of ensemble members\n",
        "x_axis = [i for i in range(1, len(members)+1)]\n",
        "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
        "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "1Jfp2a6bikQa",
        "outputId": "4d939fb7-0e29-4d06-a845-8db30d83ae80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">loaded /content/model_490.h5\n",
            ">loaded /content/model_491.h5\n",
            ">loaded /content/model_492.h5\n",
            ">loaded /content/model_493.h5\n",
            ">loaded /content/model_494.h5\n",
            ">loaded /content/model_495.h5\n",
            ">loaded /content/model_496.h5\n",
            ">loaded /content/model_497.h5\n",
            ">loaded /content/model_498.h5\n",
            ">loaded /content/model_499.h5\n",
            "Loaded 10 models\n",
            "> 1: single=0.802, ensemble=0.802\n",
            "> 2: single=0.802, ensemble=0.802\n",
            "> 3: single=0.804, ensemble=0.803\n",
            "> 4: single=0.808, ensemble=0.803\n",
            "> 5: single=0.809, ensemble=0.804\n",
            "> 6: single=0.809, ensemble=0.804\n",
            "> 7: single=0.810, ensemble=0.804\n",
            "> 8: single=0.808, ensemble=0.806\n",
            "> 9: single=0.811, ensemble=0.807\n",
            "> 10: single=0.811, ensemble=0.807\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exponentially decreasing weighted average of models on blobs problem\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.models import clone_model\n",
        "from matplotlib import pyplot\n",
        "from numpy import average\n",
        "from numpy import array\n",
        "from math import exp\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_start, n_end):\n",
        "  all_models = list()\n",
        "  for epoch in range(n_start, n_end):\n",
        "    # define filename for this ensemble\n",
        "    filename = '/content/model_' + str(epoch) + '.h5'\n",
        "    # load model from file\n",
        "    model = load_model(filename)\n",
        "    # add to list of members\n",
        "    all_models.append(model)\n",
        "    print('>loaded %s' % filename)\n",
        "  return all_models\n",
        "\n",
        "# create a model from the weights of multiple models\n",
        "def model_weight_ensemble(members, weights):\n",
        "  # determine how many layers need to be averaged\n",
        "  n_layers = len(members[0].get_weights())\n",
        "  # create an set of average model weights\n",
        "  avg_model_weights = list()\n",
        "  for layer in range(n_layers):\n",
        "    # collect this layer from each model\n",
        "    layer_weights = array([model.get_weights()[layer] for model in members])\n",
        "    # weighted average of weights for this layer\n",
        "    avg_layer_weights = average(layer_weights, axis=0, weights=weights)\n",
        "    # store average layer weights\n",
        "    avg_model_weights.append(avg_layer_weights)\n",
        "  # create a new model with the same structure\n",
        "  model = clone_model(members[0])\n",
        "  # set the weights in the new\n",
        "  model.set_weights(avg_model_weights)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "  # select a subset of members\n",
        "  subset = members[:n_members]\n",
        "  # prepare an array of exponentially decreasing weights\n",
        "  alpha = 2.0\n",
        "  weights = [exp(-i/alpha) for i in range(1, n_members+1)]\n",
        "  # create a new model with the weighted average of all model weights\n",
        "  model = model_weight_ensemble(subset, weights)\n",
        "  # make predictions and evaluate accuracy\n",
        "  _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "  return test_acc\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# load models in order\n",
        "members = load_all_models(490, 500)\n",
        "print('Loaded %d models' % len(members))\n",
        "# reverse loaded models so we build the ensemble with the last models first\n",
        "members = list(reversed(members))\n",
        "# evaluate different numbers of ensembles on hold out set\n",
        "single_scores, ensemble_scores = list(), list()\n",
        "for i in range(1, len(members)+1):\n",
        "  # evaluate model with i members\n",
        "  ensemble_score = evaluate_n_members(members, i, testX, testy)\n",
        "  # evaluate the i'th model standalone\n",
        "  _, single_score = members[i-1].evaluate(testX, testy, verbose=0)\n",
        "  # summarize this step\n",
        "  print('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
        "  ensemble_scores.append(ensemble_score)\n",
        "  single_scores.append(single_score)\n",
        "# plot score vs number of ensemble members\n",
        "x_axis = [i for i in range(1, len(members)+1)]\n",
        "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
        "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "hsBqcMS-i3Hy",
        "outputId": "6c27bf18-0b16-4f78-9b3a-32b56c56cf0a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">loaded /content/model_490.h5\n",
            ">loaded /content/model_491.h5\n",
            ">loaded /content/model_492.h5\n",
            ">loaded /content/model_493.h5\n",
            ">loaded /content/model_494.h5\n",
            ">loaded /content/model_495.h5\n",
            ">loaded /content/model_496.h5\n",
            ">loaded /content/model_497.h5\n",
            ">loaded /content/model_498.h5\n",
            ">loaded /content/model_499.h5\n",
            "Loaded 10 models\n",
            "> 1: single=0.802, ensemble=0.802\n",
            "> 2: single=0.802, ensemble=0.802\n",
            "> 3: single=0.804, ensemble=0.803\n",
            "> 4: single=0.808, ensemble=0.803\n",
            "> 5: single=0.809, ensemble=0.803\n",
            "> 6: single=0.809, ensemble=0.804\n",
            "> 7: single=0.810, ensemble=0.804\n",
            "> 8: single=0.808, ensemble=0.804\n",
            "> 9: single=0.811, ensemble=0.804\n",
            "> 10: single=0.811, ensemble=0.804\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled56.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAGwIHXgP2JS"
      },
      "source": [
        "**Linear Discriminant Analysis**\n",
        "  * Assumes gaussian distribution for numeric input variable\n",
        "  * Uses statistical technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGhvD44JPzz5"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VehRuwg3QSq3"
      },
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEHnJogsQlOz",
        "outputId": "e0654875-406f-41f6-836b-45dc9e8e8169"
      },
      "source": [
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9582417582417583"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQU9wCzdR5nU",
        "outputId": "780ba7c6-1245-401b-af6f-d5c9fa421e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "help(LinearDiscriminantAnalysis)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class LinearDiscriminantAnalysis in module sklearn.discriminant_analysis:\n",
            "\n",
            "class LinearDiscriminantAnalysis(sklearn.base.BaseEstimator, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.TransformerMixin)\n",
            " |  LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001)\n",
            " |  \n",
            " |  Linear Discriminant Analysis\n",
            " |  \n",
            " |  A classifier with a linear decision boundary, generated by fitting class\n",
            " |  conditional densities to the data and using Bayes' rule.\n",
            " |  \n",
            " |  The model fits a Gaussian density to each class, assuming that all classes\n",
            " |  share the same covariance matrix.\n",
            " |  \n",
            " |  The fitted model can also be used to reduce the dimensionality of the input\n",
            " |  by projecting it to the most discriminative directions.\n",
            " |  \n",
            " |  .. versionadded:: 0.17\n",
            " |     *LinearDiscriminantAnalysis*.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <lda_qda>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  solver : string, optional\n",
            " |      Solver to use, possible values:\n",
            " |        - 'svd': Singular value decomposition (default).\n",
            " |          Does not compute the covariance matrix, therefore this solver is\n",
            " |          recommended for data with a large number of features.\n",
            " |        - 'lsqr': Least squares solution, can be combined with shrinkage.\n",
            " |        - 'eigen': Eigenvalue decomposition, can be combined with shrinkage.\n",
            " |  \n",
            " |  shrinkage : string or float, optional\n",
            " |      Shrinkage parameter, possible values:\n",
            " |        - None: no shrinkage (default).\n",
            " |        - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\n",
            " |        - float between 0 and 1: fixed shrinkage parameter.\n",
            " |  \n",
            " |      Note that shrinkage works only with 'lsqr' and 'eigen' solvers.\n",
            " |  \n",
            " |  priors : array, optional, shape (n_classes,)\n",
            " |      Class priors.\n",
            " |  \n",
            " |  n_components : int, optional (default=None)\n",
            " |      Number of components (<= min(n_classes - 1, n_features)) for\n",
            " |      dimensionality reduction. If None, will be set to\n",
            " |      min(n_classes - 1, n_features).\n",
            " |  \n",
            " |  store_covariance : bool, optional\n",
            " |      Additionally compute class covariance matrix (default False), used\n",
            " |      only in 'svd' solver.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |  \n",
            " |  tol : float, optional, (default 1.0e-4)\n",
            " |      Threshold used for rank estimation in SVD solver.\n",
            " |  \n",
            " |      .. versionadded:: 0.17\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  coef_ : array, shape (n_features,) or (n_classes, n_features)\n",
            " |      Weight vector(s).\n",
            " |  \n",
            " |  intercept_ : array, shape (n_classes,)\n",
            " |      Intercept term.\n",
            " |  \n",
            " |  covariance_ : array-like, shape (n_features, n_features)\n",
            " |      Covariance matrix (shared by all classes).\n",
            " |  \n",
            " |  explained_variance_ratio_ : array, shape (n_components,)\n",
            " |      Percentage of variance explained by each of the selected components.\n",
            " |      If ``n_components`` is not set then all components are stored and the\n",
            " |      sum of explained variances is equal to 1.0. Only available when eigen\n",
            " |      or svd solver is used.\n",
            " |  \n",
            " |  means_ : array-like, shape (n_classes, n_features)\n",
            " |      Class means.\n",
            " |  \n",
            " |  priors_ : array-like, shape (n_classes,)\n",
            " |      Class priors (sum to 1).\n",
            " |  \n",
            " |  scalings_ : array-like, shape (rank, n_classes - 1)\n",
            " |      Scaling of the features in the space spanned by the class centroids.\n",
            " |  \n",
            " |  xbar_ : array-like, shape (n_features,)\n",
            " |      Overall mean.\n",
            " |  \n",
            " |  classes_ : array-like, shape (n_classes,)\n",
            " |      Unique class labels.\n",
            " |  \n",
            " |  See also\n",
            " |  --------\n",
            " |  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis: Quadratic\n",
            " |      Discriminant Analysis\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default solver is 'svd'. It can perform both classification and\n",
            " |  transform, and it does not rely on the calculation of the covariance\n",
            " |  matrix. This can be an advantage in situations where the number of features\n",
            " |  is large. However, the 'svd' solver cannot be used with shrinkage.\n",
            " |  \n",
            " |  The 'lsqr' solver is an efficient algorithm that only works for\n",
            " |  classification. It supports shrinkage.\n",
            " |  \n",
            " |  The 'eigen' solver is based on the optimization of the between class\n",
            " |  scatter to within class scatter ratio. It can be used for both\n",
            " |  classification and transform, and it supports shrinkage. However, the\n",
            " |  'eigen' solver needs to compute the covariance matrix, so it might not be\n",
            " |  suitable for situations with a high number of features.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> import numpy as np\n",
            " |  >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
            " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
            " |  >>> y = np.array([1, 1, 1, 2, 2, 2])\n",
            " |  >>> clf = LinearDiscriminantAnalysis()\n",
            " |  >>> clf.fit(X, y)\n",
            " |  LinearDiscriminantAnalysis()\n",
            " |  >>> print(clf.predict([[-0.8, -1]]))\n",
            " |  [1]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      LinearDiscriminantAnalysis\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.linear_model._base.LinearClassifierMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y)\n",
            " |      Fit LinearDiscriminantAnalysis model according to the given\n",
            " |         training data and parameters.\n",
            " |      \n",
            " |         .. versionchanged:: 0.19\n",
            " |            *store_covariance* has been moved to main constructor.\n",
            " |      \n",
            " |         .. versionchanged:: 0.19\n",
            " |            *tol* has been moved to main constructor.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_samples, n_features)\n",
            " |          Training data.\n",
            " |      \n",
            " |      y : array, shape (n_samples,)\n",
            " |          Target values.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Estimate log probability.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_samples, n_features)\n",
            " |          Input data.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : array, shape (n_samples, n_classes)\n",
            " |          Estimated log probabilities.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Estimate probability.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_samples, n_features)\n",
            " |          Input data.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : array, shape (n_samples, n_classes)\n",
            " |          Estimated probabilities.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Project data to maximize class separation.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_samples, n_features)\n",
            " |          Input data.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : array, shape (n_samples, n_components)\n",
            " |          Transformed data.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Predict confidence scores for samples.\n",
            " |      \n",
            " |      The confidence score for a sample is the signed distance of that\n",
            " |      sample to the hyperplane.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
            " |          Samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
            " |          Confidence scores per (sample, class) combination. In the binary\n",
            " |          case, confidence score for self.classes_[1] where >0 means this\n",
            " |          class would be predicted.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict class labels for samples in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
            " |          Samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      C : array, shape [n_samples]\n",
            " |          Predicted class label per sample.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of self.predict(X) wrt. y.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  fit_transform(self, X, y=None, **fit_params)\n",
            " |      Fit to data, then transform it.\n",
            " |      \n",
            " |      Fits transformer to X and y with optional parameters fit_params\n",
            " |      and returns a transformed version of X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : numpy array of shape [n_samples, n_features]\n",
            " |          Training set.\n",
            " |      \n",
            " |      y : numpy array of shape [n_samples]\n",
            " |          Target values.\n",
            " |      \n",
            " |      **fit_params : dict\n",
            " |          Additional fit parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
            " |          Transformed array.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}